{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6d73f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "books = pd.read_csv(\"books_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca6805c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "categories\n",
       "Fiction                       2111\n",
       "Juvenile Fiction               390\n",
       "Biography & Autobiography      311\n",
       "History                        207\n",
       "Literary Criticism             124\n",
       "                              ... \n",
       "Aged women                       1\n",
       "Imperialism                      1\n",
       "Human-animal relationships       1\n",
       "Amish                            1\n",
       "Human cloning                    1\n",
       "Name: count, Length: 479, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books['categories'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5b8500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>categories</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fiction</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Juvenile Fiction</td>\n",
       "      <td>390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Biography &amp; Autobiography</td>\n",
       "      <td>311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>History</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Literary Criticism</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Religion</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Philosophy</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Comics &amp; Graphic Novels</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Drama</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Juvenile Nonfiction</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Science</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Poetry</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   categories  count\n",
       "0                     Fiction   2111\n",
       "1            Juvenile Fiction    390\n",
       "2   Biography & Autobiography    311\n",
       "3                     History    207\n",
       "4          Literary Criticism    124\n",
       "5                    Religion    117\n",
       "6                  Philosophy    117\n",
       "7     Comics & Graphic Novels    116\n",
       "8                       Drama     86\n",
       "9         Juvenile Nonfiction     57\n",
       "10                    Science     56\n",
       "11                     Poetry     51"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[\"categories\"].value_counts().reset_index().query(\"count > 50\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4e7a0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(390, 13)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books['categories'] == \"Juvenile Fiction\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5137b4a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 13)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[books['categories'] == \"Juvenile Nonfiction\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd64340",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_mapping = {\n",
    "    'Fiction': \"Fiction\",\n",
    "    'Juvenile Fiction': \"Children's Fiction\",\n",
    "    'Biology & Autobiography': \"Nonfiction\",\n",
    "    'History': \"Nonfiction\",\n",
    "    'Literary Criticism': \"Nonfiction\",\n",
    "    'Philosophy': \"Nonfiction\",\n",
    "    'Religion': \"Nonfiction\",\n",
    "    'Comics & Graphic Novels': \"Fiction\",\n",
    "    'Drama': \"Fiction\",\n",
    "    'Juvenile Nonfiction': \"Children's Nonfiction\",\n",
    "    'Science': \"Nonfiction\",\n",
    "    'Poetry': \"Fiction\"\n",
    "}\n",
    "\n",
    "books['simple_categories'] = books['categories'].map(category_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4600ed99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn13</th>\n",
       "      <th>isbn10</th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>categories</th>\n",
       "      <th>thumbnail</th>\n",
       "      <th>description</th>\n",
       "      <th>published_year</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>num_pages</th>\n",
       "      <th>ratings_count</th>\n",
       "      <th>title_and_subtitle</th>\n",
       "      <th>tagged_description</th>\n",
       "      <th>simple_categories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9780002005883</td>\n",
       "      <td>0002005883</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>Marilynne Robinson</td>\n",
       "      <td>Fiction</td>\n",
       "      <td>http://books.google.com/books/content?id=KQZCP...</td>\n",
       "      <td>A NOVEL THAT READERS and critics have been eag...</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>247.0</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Gilead</td>\n",
       "      <td>9780002005883 A NOVEL THAT READERS and critics...</td>\n",
       "      <td>Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9780002261982</td>\n",
       "      <td>0002261987</td>\n",
       "      <td>Spider's Web</td>\n",
       "      <td>Charles Osborne;Agatha Christie</td>\n",
       "      <td>Detective and mystery stories</td>\n",
       "      <td>http://books.google.com/books/content?id=gA5GP...</td>\n",
       "      <td>A new 'Christie for Christmas' -- a full-lengt...</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.83</td>\n",
       "      <td>241.0</td>\n",
       "      <td>5164.0</td>\n",
       "      <td>Spider's Web: A Novel</td>\n",
       "      <td>9780002261982 A new 'Christie for Christmas' -...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          isbn13      isbn10         title                          authors  \\\n",
       "0  9780002005883  0002005883        Gilead               Marilynne Robinson   \n",
       "1  9780002261982  0002261987  Spider's Web  Charles Osborne;Agatha Christie   \n",
       "\n",
       "                      categories  \\\n",
       "0                        Fiction   \n",
       "1  Detective and mystery stories   \n",
       "\n",
       "                                           thumbnail  \\\n",
       "0  http://books.google.com/books/content?id=KQZCP...   \n",
       "1  http://books.google.com/books/content?id=gA5GP...   \n",
       "\n",
       "                                         description  published_year  \\\n",
       "0  A NOVEL THAT READERS and critics have been eag...          2004.0   \n",
       "1  A new 'Christie for Christmas' -- a full-lengt...          2000.0   \n",
       "\n",
       "   average_rating  num_pages  ratings_count     title_and_subtitle  \\\n",
       "0            3.85      247.0          361.0                 Gilead   \n",
       "1            3.83      241.0         5164.0  Spider's Web: A Novel   \n",
       "\n",
       "                                  tagged_description simple_categories  \n",
       "0  9780002005883 A NOVEL THAT READERS and critics...           Fiction  \n",
       "1  9780002261982 A new 'Christie for Christmas' -...               NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf484c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3432, 14)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books[~(books[\"simple_categories\"].isna())].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ffaa380",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Error while downloading from https://huggingface.co/facebook/bart-large-mnli/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Error while downloading from https://huggingface.co/facebook/bart-large-mnli/resolve/main/model.safetensors: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n",
      "Trying to resume download...\n",
      "Device set to use mps\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "PyTorch is not linked with support for mps devices",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[32m      3\u001b[39m fiction_categories = [\u001b[33m\"\u001b[39m\u001b[33mFiction\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mNonfiction\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m pipe=\u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mzero-shot-classification\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m              \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfacebook/bart-large-mnli\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m              \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\transformers\\pipelines\\__init__.py:1268\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m processor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mprocessor\u001b[39m\u001b[33m\"\u001b[39m] = processor\n\u001b[32m-> \u001b[39m\u001b[32m1268\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[43m=\u001b[49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\transformers\\pipelines\\zero_shot_classification.py:87\u001b[39m, in \u001b[36mZeroShotClassificationPipeline.__init__\u001b[39m\u001b[34m(self, args_parser, *args, **kwargs)\u001b[39m\n\u001b[32m     85\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args_parser=ZeroShotClassificationArgumentHandler(), *args, **kwargs):\n\u001b[32m     86\u001b[39m     \u001b[38;5;28mself\u001b[39m._args_parser = args_parser\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.entailment_id == -\u001b[32m1\u001b[39m:\n\u001b[32m     89\u001b[39m         logger.warning(\n\u001b[32m     90\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFailed to determine \u001b[39m\u001b[33m'\u001b[39m\u001b[33mentailment\u001b[39m\u001b[33m'\u001b[39m\u001b[33m label id from the label2id mapping in the model config. Setting to \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     91\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m-1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     92\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1049\u001b[39m, in \u001b[36mPipeline.__init__\u001b[39m\u001b[34m(self, model, tokenizer, feature_extractor, image_processor, processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate as well as the case that model is already on device\u001b[39;00m\n\u001b[32m   1043\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m   1044\u001b[39m     \u001b[38;5;28mself\u001b[39m.framework == \u001b[33m\"\u001b[39m\u001b[33mpt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1045\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.device != \u001b[38;5;28mself\u001b[39m.device\n\u001b[32m   1046\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.device, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device < \u001b[32m0\u001b[39m)\n\u001b[32m   1047\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1048\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[38;5;66;03m# If it's a generation pipeline and the model can generate:\u001b[39;00m\n\u001b[32m   1052\u001b[39m \u001b[38;5;66;03m# 1 - create a local generation config. This is done to avoid side-effects on the model as we apply local\u001b[39;00m\n\u001b[32m   1053\u001b[39m \u001b[38;5;66;03m# tweaks to the generation config.\u001b[39;00m\n\u001b[32m   1054\u001b[39m \u001b[38;5;66;03m# 2 - load the assistant model if it is passed.\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pipeline_calls_generate \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model.can_generate():\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\transformers\\modeling_utils.py:4110\u001b[39m, in \u001b[36mPreTrainedModel.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   4105\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[32m   4106\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   4107\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4108\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   4109\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m4110\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1355\u001b[39m, in \u001b[36mModule.to\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1352\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1353\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1355\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:915\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.children():\n\u001b[32m--> \u001b[39m\u001b[32m915\u001b[39m         \u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[32m    919\u001b[39m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[32m    920\u001b[39m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    925\u001b[39m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[32m    926\u001b[39m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:942\u001b[39m, in \u001b[36mModule._apply\u001b[39m\u001b[34m(self, fn, recurse)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[32m    939\u001b[39m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[32m    940\u001b[39m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     param_applied = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    943\u001b[39m p_should_use_set_data = compute_should_use_set_data(param, param_applied)\n\u001b[32m    945\u001b[39m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\LENOVO\\Desktop\\BookRecommendatioin\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1341\u001b[39m, in \u001b[36mModule.to.<locals>.convert\u001b[39m\u001b[34m(t)\u001b[39m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t.dim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m):\n\u001b[32m   1335\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m t.to(\n\u001b[32m   1336\u001b[39m             device,\n\u001b[32m   1337\u001b[39m             dtype \u001b[38;5;28;01mif\u001b[39;00m t.is_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t.is_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1338\u001b[39m             non_blocking,\n\u001b[32m   1339\u001b[39m             memory_format=convert_to_format,\n\u001b[32m   1340\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1341\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1342\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1343\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1344\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1346\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1347\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) == \u001b[33m\"\u001b[39m\u001b[33mCannot copy out of meta tensor; no data!\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mRuntimeError\u001b[39m: PyTorch is not linked with support for mps devices"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "fiction_categories = [\"Fiction\", \"Nonfiction\"]\n",
    "\n",
    "\n",
    "pipe=pipeline(\"zero-shot-classification\", \n",
    "              model=\"facebook/bart-large-mnli\",\n",
    "              device='mps')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e87145",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = books.loc[books['simple_categories'] == \"Fiction\", \"description\"].reset_index(drop=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4ec4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe(sequence, fiction_categories)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4383bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gettign the predicted label \n",
    "import numpy as np \n",
    "\n",
    "max_index = np.argmax(pipe(sequence, fiction_categories)['scores'])\n",
    "\n",
    "max_label = pipe(sequence, fiction_categories)[\"labels\"][max_index]\n",
    "max_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aae43ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_predictions(sequence, categories):\n",
    "    predictions = pipe(sequence, categories)[\"labels\"]\n",
    "    max_index = np.argmax(predictions['scores'])\n",
    "    max_label = predictions[\"labels\"][max_index]\n",
    "    return max_label\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing \n",
    "from tqdm import tqdm\n",
    "# To calculate the time taken for execution\n",
    "\n",
    "actual_cats = []\n",
    "predicted_cats = []\n",
    "\n",
    "for i in tqdm(range(0, 300)):\n",
    "    sequence = books.loc[books[\"simple_categories\"] == \"Fiction\", \"description\"].reset_index(drop=True)[i]\n",
    "    predicted_cat += generate_predictions(sequence, fiction_categories)\n",
    "    actual_cats += [\"Fiction\"]\n",
    "\n",
    "for i in tqdm(range(0, 300)):\n",
    "    sequence = books.loc[books[\"simple_categories\"] == \"Nonfiction\", \"description\"].reset_index(drop=True)[i]\n",
    "    predicted_cat += generate_predictions(sequence, fiction_categories)\n",
    "    actual_cats += [\"Nonfiction\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce02fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_df = pd.DataFrame({\"actual_categories\": actual_cats, \"predicted_categories\": predicted_cats})\n",
    "\n",
    "predictions_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82404f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions_df[\"correct_predictions\"] = (\n",
    "    np.where(predictions_df['actual_categories'] == predictions_df['predicted_categories'], 1, 0)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2564a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df[\"correct_prediction\"].sum() / len(predictions_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243f6ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "isbns=[]\n",
    "predicted_cats = []\n",
    "\n",
    "missing_cats = books.loc[books[\"simple_categories\"].isna(), [\"isbn13\", \"description\"]].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364f0e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(0, len(missing_cats))):\n",
    "    sequence = missing_cats[\"description\"][i]\n",
    "    predicted_cats += [generate_predictions(sequence, fiction_categories)]\n",
    "    isbns += [missing_cats[\"isbn13\"][i]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fb5aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_predicted_df = pd.DataFrame({\"isbn13\": isbns, \"predicted_categories\": predicted_cats})\n",
    "missing_predicted_df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4d7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.merge(books, missing_predicted_df, on=\"isbns13\", how=\"left\")\n",
    "books[\"simple_categories\"] = np.where(books[\"simple_categories\"].isna(), books[\"predicted_categories\", books[\"predicted_categories\"], books[\"simple_categories\"]])\n",
    "books = books.drop(columns=[\"predicted_categories\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a314201d",
   "metadata": {},
   "outputs": [],
   "source": [
    "books[books[\"categories\"].str.lower().isin([\n",
    "    \"romance\",\n",
    "    \"science fiction\",\n",
    "    \"scifi\",\n",
    "    \"fantasy\",\n",
    "    \"horror\",\n",
    "    \"mystery\",\n",
    "    \"thriller\",\n",
    "    \"comedy\",\n",
    "    \"crime\", \n",
    "    \"historical\"\n",
    "])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaddf0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "books.to_csv(\"books_with_categories.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
